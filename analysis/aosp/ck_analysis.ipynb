{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from subprocess import PIPE, STDOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer in /home/davit/Projects/UFC/Qualificacao/analysis/.venv/lib/python3.10/site-packages (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install charset-normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.exc import IntegrityError\n",
    "from bs4 import UnicodeDammit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename=\"HISTORYlistener.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s.%(msecs)03d %(levelname)s %(module)s - %(funcName)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINTS_PATH = \"checkpoints_ck.txt\"\n",
    "AOSP_SYNC_PATH = \"/mnt/4846A54B46A53A98/AOSP/\"\n",
    "AOSP_ROOT_MATCHER = \"<AOSP_ROOT>/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoints():\n",
    "    if os.path.exists(CHECKPOINTS_PATH):\n",
    "        with open(CHECKPOINTS_PATH, \"r\") as checkpoint_file:\n",
    "            lines = checkpoint_file.readlines()\n",
    "            lines = [line.strip() for line in lines]\n",
    "            return lines\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "def save_checkpoint(path):\n",
    "    with open(CHECKPOINTS_PATH, \"a\") as checkpoint_file:\n",
    "        checkpoint_file.write(path + \"\\n\")\n",
    "    logger.info(f\"saved checkpoint on {path}\")\n",
    "\n",
    "def copy_results(destination_folder):\n",
    "    GENERATED_FILES = ['class.csv', 'field.csv', 'method.csv', 'variable.csv']\n",
    "    for file in GENERATED_FILES:\n",
    "        src = f\"./{file}\"\n",
    "        destination_file = destination_folder + f\"/{file}\"\n",
    "        if not os.path.exists(destination_folder):\n",
    "            os.makedirs(destination_folder)\n",
    "        shutil.copy(src, destination_file)\n",
    "        logger.info(f\"Copied {src} into {destination_file}\")\n",
    "def log_subprocess_output(pipe):\n",
    "    for line in iter(pipe.readline, b''): # b'\\n'-separated lines\n",
    "        logger.info('got line from subprocess: %r', line)\n",
    "def gen_output_folder(git_dir_norm: str):\n",
    "    return \"./ck_output/aosp/\" + git_dir_norm.split(AOSP_ROOT_MATCHER)[-1]\n",
    "def gen_aosp_folder(git_dir_norm: str):\n",
    "    return AOSP_SYNC_PATH + git_dir_norm.split(AOSP_ROOT_MATCHER)[-1]\n",
    "def load_txt(path: str):\n",
    "    with open(path, \"r\") as txt_file:\n",
    "        return [line.strip() for line in txt_file.readlines()]\n",
    "def get_loc(java_file_path):\n",
    "    # get encoding\n",
    "    logger.info(f\"Processing encoding on {java_file_path}\")\n",
    "    with open(java_file_path, \"rb\") as java_file:\n",
    "        java_file_bytes = java_file.read()\n",
    "        ud = UnicodeDammit(java_file_bytes)\n",
    "        enc = ud.original_encoding\n",
    "\n",
    "        if enc is None:\n",
    "            logger.critical(f\"Could not get encoding for file {java_file_path}, got None.\")\n",
    "            logger.warning(\"Trying utf-8\")\n",
    "            enc = 'utf-8'\n",
    "        else:\n",
    "            logger.info(f\"Detected encoding: {enc}\")\n",
    "        buffer = java_file_bytes.decode(encoding=enc)\n",
    "    return len(buffer.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CK_JAR_PATH = \"../tools/ck.jar\"\n",
    "def run_ck(java_file_path):\n",
    "    java_dir_path = gen_aosp_folder(dir)\n",
    "    process = subprocess.Popen([\"java\", \"-jar\", CK_JAR_PATH, java_dir_path], stdout=PIPE, stderr=STDOUT)\n",
    "    with process.stdout:\n",
    "        log_subprocess_output(process.stdout)\n",
    "    if process.wait() != 0:\n",
    "        logger.critical(f\"Error executing {java_file_path}\")\n",
    "        error_msg = \"Return code is not zero, error in execution of ck. Check logs.\"\n",
    "        logger.critical(error_msg)\n",
    "        raise RuntimeError(error_msg)\n",
    "    ck_output = gen_output_folder(java_file_path)\n",
    "    copy_results(ck_output)\n",
    "    save_checkpoint(java_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN CK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = load_checkpoints()\n",
    "git_dirs_norm = load_txt(\"./git_dirs_NORM.txt\")\n",
    "files_to_run = (file for file in git_dirs_norm if file not in checkpoints)\n",
    "for dir in files_to_run:\n",
    "    try:\n",
    "        run_ck(dir)\n",
    "    except:\n",
    "        with open(\"./checkpoints_ck_failed.txt\", 'a') as txt_file:\n",
    "            txt_file.write(dir + '\\n')\n",
    "        save_checkpoint(dir)\n",
    "        logger.error(f\"Failed to run ck on {dir}. Skipping to the next.\")\n",
    "        print(f\"Failed to run ck on {dir}. Skipping to the next.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate into SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, select\n",
    "from sqlalchemy import ForeignKey\n",
    "from sqlalchemy import String, Integer, Double, Float, Boolean\n",
    "from sqlalchemy.orm import DeclarativeBase\n",
    "from sqlalchemy.orm import Mapped\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from sqlalchemy.orm import relationship\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base(DeclarativeBase):\n",
    "    pass\n",
    "\n",
    "class AOSPBase(DeclarativeBase):\n",
    "    pass\n",
    "\n",
    "class Project(Base):\n",
    "    __tablename__ = \"projects\"\n",
    "    name = mapped_column(String(), nullable=False, unique=True, primary_key=True)\n",
    "    files: Mapped[List[\"File\"]] = relationship(back_populates=\"project\")\n",
    "    aoc_reports: Mapped[List[\"AoCReport\"]] = relationship()\n",
    "\n",
    "class File(Base):\n",
    "    __tablename__ = \"files\"\n",
    "    path: Mapped[str] = mapped_column(String(), nullable=False, unique=True, primary_key=True)\n",
    "    loc: Mapped[int] = mapped_column(Integer())\n",
    "    classes: Mapped[List[\"Klass\"]] = relationship(back_populates=\"file\")\n",
    "    project: Mapped[Project] = relationship(back_populates=\"files\")\n",
    "    project_name: Mapped[str] = mapped_column(ForeignKey(\"projects.name\"))\n",
    "\n",
    "class Klass(Base):\n",
    "    __tablename__ = \"classes\"\n",
    "    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n",
    "    file: Mapped[File] = relationship(back_populates=\"classes\")\n",
    "    methods: Mapped[List[\"Method\"]] = relationship(back_populates=\"class_\")\n",
    "    file_path: Mapped[str] = mapped_column(ForeignKey(\"files.path\"))\n",
    "    name: Mapped[str] = mapped_column(String(), nullable=False)\n",
    "    type_: Mapped[str] = mapped_column(String(), nullable=False, name=\"type\")\n",
    "    cbo: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    cboModified: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    fanin: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    fanout: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    wmc: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    dit: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    noc: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    rfc: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    lcom: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    lcom_normalized: Mapped[float] = mapped_column(Double(), nullable=True)\n",
    "    tcc: Mapped[float] = mapped_column(Double(), nullable=True)\n",
    "    lcc: Mapped[float] = mapped_column(Double(), nullable=True)\n",
    "    totalMethodsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    staticMethodsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    publicMethodsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    privateMethodsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    protectedMethodsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    defaultMethodsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    visibleMethodsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    abstractMethodsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    finalMethodsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    synchronizedMethodsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    totalFieldsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    staticFieldsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    publicFieldsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    privateFieldsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    protectedFieldsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    defaultFieldsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    finalFieldsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    synchronizedFieldsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    nosi: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    loc: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    returnQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    loopQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    comparisonsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    tryCatchQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    parenthesizedExpsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    stringLiteralsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    numbersQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    assignmentsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    mathOperationsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    variablesQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    maxNestedBlocksQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    anonymousClassesQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    innerClassesQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    lambdasQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    uniqueWordsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    modifiers: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    logStatementsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "\n",
    "class Method(Base):\n",
    "    __tablename__ = \"methods\"\n",
    "    id_: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n",
    "    file: Mapped[File] = relationship()\n",
    "    class_: Mapped[Klass] = relationship(back_populates=\"methods\")\n",
    "    file_path: Mapped[str] = mapped_column(ForeignKey(\"files.path\"))\n",
    "    class_id: Mapped[int] = mapped_column(ForeignKey(\"classes.id\"))\n",
    "    name: Mapped[str] = mapped_column(String(), nullable=False)\n",
    "    constructor: Mapped[bool] = mapped_column(Boolean(), nullable=False)\n",
    "    line: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    cbo: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    cboModified: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    fanin: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    fanout: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    wmc: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    rfc: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    loc: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    returnsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    variablesQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    parametersQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    methodsInvokedQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    methodsInvokedLocalQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    methodsInvokedIndirectLocalQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    loopQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    comparisonsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    tryCatchQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    parenthesizedExpsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    stringLiteralsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    numbersQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    assignmentsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    mathOperationsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    maxNestedBlocksQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    anonymousClassesQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    innerClassesQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    lambdasQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    uniqueWordsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    modifiers: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    logStatementsQty: Mapped[int] = mapped_column(Integer(), nullable=True)\n",
    "    hasJavaDoc: Mapped[bool] = mapped_column(Boolean(), nullable=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AOSPProject(AOSPBase):\n",
    "    __tablename__ = \"aosp_projects\"\n",
    "    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n",
    "    name: Mapped[str] = mapped_column(String(), nullable=False)\n",
    "    description: Mapped[str] = mapped_column(String(), nullable=True)\n",
    "    package: Mapped[str] = mapped_column(String(), nullable=False)\n",
    "    category: Mapped[str] = mapped_column(String(), nullable=False)\n",
    "    aoc_reports: Mapped[List[\"AOSPAoCReport\"]] = relationship(back_populates=\"project\")\n",
    "\n",
    "class AOSPAoCReport(AOSPBase):\n",
    "    __tablename__ = \"aosp_aoc_reports\"\n",
    "    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n",
    "    project_id: Mapped[int] = mapped_column(ForeignKey(\"aosp_projects.id\"))\n",
    "    project: Mapped[\"AOSPProject\"] = relationship(back_populates=\"aoc_reports\")\n",
    "    line: Mapped[int] = mapped_column(Integer())\n",
    "    snippet: Mapped[str] = mapped_column(String(), nullable=False)\n",
    "    class_: Mapped[str] = mapped_column(String(), nullable=False, name=\"class\")\n",
    "    aoc: Mapped[str] = mapped_column(String(), nullable=False)\n",
    "    path: Mapped[str] = mapped_column(String(), nullable=True)\n",
    "    commit: Mapped[str] = mapped_column(String(), nullable=True)\n",
    "    loc: Mapped[int] = mapped_column(String(), nullable=True)\n",
    "\n",
    "class AoCReport(Base):\n",
    "    __tablename__ = \"aoc_reports\"\n",
    "    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n",
    "    project_name: Mapped[str] = mapped_column(ForeignKey(\"projects.name\"))\n",
    "    project: Mapped[\"Project\"] = relationship(back_populates=\"aoc_reports\")\n",
    "    line: Mapped[int] = mapped_column(Integer())\n",
    "    snippet: Mapped[str] = mapped_column(String(), nullable=False)\n",
    "    class_name: Mapped[str] = mapped_column(String(), nullable=True)\n",
    "    aoc: Mapped[str] = mapped_column(String(), nullable=False)\n",
    "    path: Mapped[str] = mapped_column(String(), nullable=True)\n",
    "    commit: Mapped[str] = mapped_column(String(), nullable=True)\n",
    "    loc: Mapped[int] = mapped_column(String(), nullable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = create_engine(\"sqlite+pysqlite:///aosp_ck_output.db\")\n",
    "aosp_aoc_db = create_engine(\"sqlite+pysqlite:///aosp_dataset.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Base.metadata.create_all(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_class(class_name, file_name) -> Klass:\n",
    "    with Session(db) as session:\n",
    "        stmt = select(Klass).where(Klass.name.like(f\"%{class_name}%\") & Klass.file_path.like(file_name))\n",
    "        return session.scalar(stmt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query from AOC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reports_by_project(project: AOSPProject) -> List[AOSPAoCReport]:\n",
    "    stmt = select(AOSPAoCReport).where(AOSPAoCReport.project_id == project.id)\n",
    "    with Session(aosp_aoc_db) as session:\n",
    "        exec = session.execute(stmt, execution_options={\"prebuffer_rows\": True})\n",
    "        return exec.scalars()\n",
    "def get_aosp_project_by_name(name: str) -> AOSPProject:\n",
    "    with Session(aosp_aoc_db) as session:\n",
    "        return session.query(AOSPProject).filter(AOSPProject.name.like(name)).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classes_sqlalchemy(df: pd.DataFrame) -> List[Klass]:\n",
    "    classes = []\n",
    "    for i, row in df.iterrows():\n",
    "        c = Klass(\n",
    "            file_path=row[\"file\"],\n",
    "            name=row[\"class\"],\n",
    "            type_=row[\"type\"],\n",
    "            cbo=row[\"cbo\"],\n",
    "            cboModified=row[\"cboModified\"],\n",
    "            fanin=row[\"fanin\"],\n",
    "            fanout=row[\"fanout\"],\n",
    "            wmc=row[\"wmc\"],\n",
    "            dit=row[\"dit\"],\n",
    "            noc=row[\"noc\"],\n",
    "            rfc=row[\"rfc\"],\n",
    "            lcom=row[\"lcom\"],\n",
    "            lcom_normalized=row[\"lcom*\"],\n",
    "            tcc=row[\"tcc\"],\n",
    "            lcc=row[\"lcc\"],\n",
    "            totalMethodsQty=row[\"totalMethodsQty\"],\n",
    "            staticMethodsQty=row[\"staticMethodsQty\"],\n",
    "            publicMethodsQty=row[\"publicMethodsQty\"],\n",
    "            privateMethodsQty=row[\"privateMethodsQty\"],\n",
    "            protectedMethodsQty=row[\"protectedMethodsQty\"],\n",
    "            defaultMethodsQty=row[\"defaultMethodsQty\"],\n",
    "            visibleMethodsQty=row[\"visibleMethodsQty\"],\n",
    "            abstractMethodsQty=row[\"abstractMethodsQty\"],\n",
    "            finalMethodsQty=row[\"finalMethodsQty\"],\n",
    "            synchronizedMethodsQty=row[\"synchronizedMethodsQty\"],\n",
    "            totalFieldsQty=row[\"totalFieldsQty\"],\n",
    "            staticFieldsQty=row[\"staticFieldsQty\"],\n",
    "            publicFieldsQty=row[\"publicFieldsQty\"],\n",
    "            privateFieldsQty=row[\"privateFieldsQty\"],\n",
    "            protectedFieldsQty=row[\"protectedFieldsQty\"],\n",
    "            defaultFieldsQty=row[\"defaultFieldsQty\"],\n",
    "            finalFieldsQty=row[\"finalFieldsQty\"],\n",
    "            synchronizedFieldsQty=row[\"synchronizedFieldsQty\"],\n",
    "            nosi=row[\"nosi\"],\n",
    "            loc=row[\"loc\"],\n",
    "            returnQty=row[\"returnQty\"],\n",
    "            loopQty=row[\"loopQty\"],\n",
    "            comparisonsQty=row[\"comparisonsQty\"],\n",
    "            tryCatchQty=row[\"tryCatchQty\"],\n",
    "            parenthesizedExpsQty=row[\"parenthesizedExpsQty\"],\n",
    "            stringLiteralsQty=row[\"stringLiteralsQty\"],\n",
    "            numbersQty=row[\"numbersQty\"],\n",
    "            assignmentsQty=row[\"assignmentsQty\"],\n",
    "            mathOperationsQty=row[\"mathOperationsQty\"],\n",
    "            variablesQty=row[\"variablesQty\"],\n",
    "            maxNestedBlocksQty=row[\"maxNestedBlocksQty\"],\n",
    "            anonymousClassesQty=row[\"anonymousClassesQty\"],\n",
    "            innerClassesQty=row[\"innerClassesQty\"],\n",
    "            lambdasQty=row[\"lambdasQty\"],\n",
    "            uniqueWordsQty=row[\"uniqueWordsQty\"],\n",
    "            modifiers=row[\"modifiers\"],\n",
    "            logStatementsQty=row[\"logStatementsQty\"],\n",
    "        )\n",
    "        classes.append(c)\n",
    "    return classes\n",
    "def create_methods_sqlalchemy(df: pd.DataFrame, file_path: str) -> List[Method]:\n",
    "    methods = []\n",
    "    for i, row in df.iterrows():\n",
    "        class_: Klass = query_class(row[\"class\"], row[\"file\"])\n",
    "        m = Method(\n",
    "        file_path=row[\"file\"],\n",
    "        class_id= class_.id,\n",
    "        name=row[\"method\"],\n",
    "        constructor=row[\"constructor\"],\n",
    "        line=row[\"line\"],\n",
    "        cbo=row[\"cbo\"],\n",
    "        cboModified=row[\"cboModified\"],\n",
    "        fanin=row[\"fanin\"],\n",
    "        fanout=row[\"fanout\"],\n",
    "        wmc=row[\"wmc\"],\n",
    "        rfc=row[\"rfc\"],\n",
    "        loc=row[\"loc\"],\n",
    "        returnsQty=row[\"returnsQty\"],\n",
    "        variablesQty=row[\"variablesQty\"],\n",
    "        parametersQty=row[\"parametersQty\"],\n",
    "        methodsInvokedQty=row[\"methodsInvokedQty\"],\n",
    "        methodsInvokedLocalQty=row[\"methodsInvokedLocalQty\"],\n",
    "        methodsInvokedIndirectLocalQty=row[\"methodsInvokedIndirectLocalQty\"],\n",
    "        loopQty=row[\"loopQty\"],\n",
    "        comparisonsQty=row[\"comparisonsQty\"],\n",
    "        tryCatchQty=row[\"tryCatchQty\"],\n",
    "        parenthesizedExpsQty=row[\"parenthesizedExpsQty\"],\n",
    "        stringLiteralsQty=row[\"stringLiteralsQty\"],\n",
    "        numbersQty=row[\"numbersQty\"],\n",
    "        assignmentsQty=row[\"assignmentsQty\"],\n",
    "        mathOperationsQty=row[\"mathOperationsQty\"],\n",
    "        maxNestedBlocksQty=row[\"maxNestedBlocksQty\"],\n",
    "        anonymousClassesQty=row[\"anonymousClassesQty\"],\n",
    "        innerClassesQty=row[\"innerClassesQty\"],\n",
    "        lambdasQty=row[\"lambdasQty\"],\n",
    "        uniqueWordsQty=row[\"uniqueWordsQty\"],\n",
    "        modifiers=row[\"modifiers\"],\n",
    "        logStatementsQty=row[\"logStatementsQty\"],\n",
    "        hasJavaDoc=row[\"hasJavaDoc\"]\n",
    "        )\n",
    "        methods.append(m)\n",
    "    return methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Persist Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_dirs_norm = load_txt(\"./git_dirs_NORM.txt\")\n",
    "failed_git_dirs = load_txt(\"./checkpoints_ck_failed.txt\")\n",
    "files_to_run = (f for f in git_dirs_norm if f not in failed_git_dirs)\n",
    "logger.info(\"Start persisting on sqlite\")\n",
    "for path in files_to_run:\n",
    "    logger.info(f\"Processing {path}\")\n",
    "    report_path = gen_output_folder(path)\n",
    "    aosp_file_path = gen_aosp_folder(path)\n",
    "    project_name = path.split(AOSP_ROOT_MATCHER)[-1]\n",
    "    df_class = pd.read_csv(report_path + \"/class.csv\")\n",
    "    df_method = pd.read_csv(report_path + \"/method.csv\")\n",
    "    if (df_class.empty and df_method.empty):\n",
    "        logger.info(f\"project in path {path} does not have java files. Skipping.\")\n",
    "        continue\n",
    "    proj = Project(name=project_name)\n",
    "    # Persist Classes & Methods\n",
    "    classes = create_classes_sqlalchemy(df_class)\n",
    "    logger.info(\"Saving class and project to database\")\n",
    "    with Session(db) as session:\n",
    "        session.add(proj)\n",
    "        session.add_all(classes)\n",
    "        session.commit()\n",
    "    methods = create_methods_sqlalchemy(df_method, aosp_file_path)\n",
    "    logger.info(\"Saving methods to database\")\n",
    "    with Session(db) as session:\n",
    "        session.add_all(methods)\n",
    "        session.commit()\n",
    "logger.info(\"Done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Persist files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_dirs_norm = load_txt(\"./git_dirs_NORM.txt\")\n",
    "# failed_git_dirs = load_txt(\"./checkpoints_ck_failed.txt\")\n",
    "# files_to_run = (f for f in git_dirs_norm if f not in failed_git_dirs)\n",
    "logger.info('Start persisting \"FILES\" on sqlite')\n",
    "for path in git_dirs_norm:\n",
    "    aosp_file_path = gen_aosp_folder(path)\n",
    "    project_name = path.split(AOSP_ROOT_MATCHER)[-1]\n",
    "    logger.info(f\"\\tProject: {project_name}\")\n",
    "    logger.info(f\"\\tRoot path: {aosp_file_path}\")\n",
    "    file_entries = []\n",
    "    for curpath, _, files in os.walk(aosp_file_path):\n",
    "        logger.info(f\"Adding java files on {curpath}\")\n",
    "        file_entries.extend(\n",
    "            [\n",
    "                File(\n",
    "                    path=f\"{curpath}/{java_file}\",\n",
    "                    loc=get_loc(f\"{curpath}/{java_file}\"),\n",
    "                    project_name=project_name,\n",
    "                )\n",
    "                for java_file in files\n",
    "                if java_file.endswith(\".java\")\n",
    "            ]\n",
    "        )\n",
    "    logger.info(\"Saving to database...\")\n",
    "    try:\n",
    "        with Session(db) as session:\n",
    "            session.add_all(file_entries)\n",
    "            session.commit()\n",
    "    except(IntegrityError):\n",
    "        pass #Already in the database\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Start merging\")\n",
    "git_dirs_norm = load_txt(\"./git_dirs_NORM.txt\")\n",
    "for path in git_dirs_norm:\n",
    "    logger.info(f\"On path {path}\")\n",
    "    project_name = path.split(AOSP_ROOT_MATCHER)[-1]\n",
    "    aosp_project: AOSPProject = get_aosp_project_by_name(project_name)\n",
    "    if not aosp_project:\n",
    "        logger.error(f\"No AOCS found for project {project_name}, skipping.\")\n",
    "        continue\n",
    "    aocs: List[AOSPAoCReport] = get_reports_by_project(aosp_project)\n",
    "    aocs_transformed = []\n",
    "    for aoc in aocs:\n",
    "        aocs_transformed.append(\n",
    "            AoCReport(\n",
    "                project_name=project_name,\n",
    "                line=aoc.line,\n",
    "                snippet=aoc.snippet,\n",
    "                class_name=aoc.class_,\n",
    "                aoc=aoc.aoc,\n",
    "                path=aoc.path,\n",
    "                commit=aoc.commit,\n",
    "                loc=aoc.loc,\n",
    "            )\n",
    "        )\n",
    "    with Session(db) as session:\n",
    "        logger.info(\"Saving to database...\")\n",
    "        session.add_all(aocs_transformed)\n",
    "        session.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
