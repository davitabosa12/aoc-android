{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install github\n",
    "# pip install tqdm\n",
    "# pip install python-dotenv\n",
    "# pip install gitpython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import github\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import git\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "load_dotenv()\n",
    "tqdm.pandas()\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(\"ETL\")\n",
    "logging.basicConfig(format='%(asctime)s %(levelname):%(message)', level=logging.DEBUG, datefmt='%H:%M:%S')\n",
    "logger.debug(\"ETL logging!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_USERNAME = os.getenv(\"GITHUB_USERNAME\")\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub Client setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = await github.GHClient(username=GITHUB_USERNAME, token=GITHUB_TOKEN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Droid apps list, only github apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_list = pd.read_csv(\"data/fdroid_apps_list_complete.csv\")\n",
    "apps_list = apps_list[~apps_list[\"source_code\"].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_filter = apps_list[\"source_code\"].str.contains(\"github\")\n",
    "github_apps_list = apps_list[gh_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_repo_owner(url: str) -> dict:\n",
    "    offset = -1\n",
    "    if url.endswith(\"/\"):\n",
    "        offset -= 1\n",
    "    splitted = url.split(\"/\")\n",
    "    return {\n",
    "        \"repo\": splitted[offset],\n",
    "        \"owner\": splitted[offset - 1]\n",
    "    }\n",
    "\n",
    "class DummyRepoInfo:\n",
    "    def __init__(self) -> None:\n",
    "        self.stargazers_count = None\n",
    "        self.language = None\n",
    "        self.archived = None\n",
    "        self.disabled = None\n",
    "        self.updated_at = None\n",
    "        self.clone_url = None\n",
    "        self.forks = None\n",
    "        self.is_fork = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_apps_list_complete = github_apps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_info_from_gh(df: pd.DataFrame, start_after: str = None):\n",
    "    first_line = True\n",
    "    should_skip = True if start_after else False\n",
    "    for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        if should_skip:\n",
    "            first_line = False\n",
    "            print(\"skipping\", df[\"package\"])\n",
    "            if df[\"package\"] == start_after:\n",
    "                should_skip = False\n",
    "            continue\n",
    "        row_dict = row.to_dict()\n",
    "        time.sleep(0.8)\n",
    "        try:\n",
    "            repo_info = await client.get_repo(**extract_repo_owner(row[\"source_code\"]))\n",
    "        except github.RepositoryNotFound:\n",
    "            repo_info = DummyRepoInfo()\n",
    "        row_dict[\"stars\"] = repo_info.stargazers_count\n",
    "        row_dict[\"primary_language\"] = repo_info.language\n",
    "        row_dict[\"is_archived\"] = repo_info.archived\n",
    "        row_dict[\"is_disabled\"] = repo_info.disabled\n",
    "        row_dict[\"updated_at\"] = repo_info.updated_at\n",
    "        row_dict[\"clone_url\"] = repo_info.clone_url\n",
    "        row_dict[\"forks\"] = repo_info.forks\n",
    "        row_dict[\"is_fork\"] = repo_info.is_fork\n",
    "        # Save to csv\n",
    "        with open(\"data/github_apps_list_complete.csv\", 'a') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=row_dict.keys())\n",
    "            if first_line == True:\n",
    "                first_line = False\n",
    "                writer.writeheader()\n",
    "            writer.writerow(row_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await get_info_from_gh(github_apps_list) # uncomment for ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_apps_list_complete = pd.read_csv(\"data/github_apps_list_complete.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of projects by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_apps_list_complete[\"primary_language\"].value_counts().head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of stars by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_apps_list_complete.groupby([\"primary_language\"])[\"stars\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of forks by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_apps_list_complete.groupby([\"primary_language\"])[\"forks\"].sum().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Java projects with most stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_filter = (github_apps_list_complete[\"primary_language\"] == \"Java\").fillna(False)\n",
    "java_github_top20 = github_apps_list_complete[java_filter] \\\n",
    "        .sort_values(\"stars\", ascending=False) \\\n",
    "        .drop_duplicates(subset=[\"clone_url\"]) \\\n",
    "        .head(20)\n",
    "java_github_top20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clone repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, repo in java_github_top20.iterrows():\n",
    "    git.Git(\"../repos/\").clone(repo[\"clone_url\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run BOHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINTS_PATH = \"data/bohr_checkpoints.txt\"\n",
    "def has_java_files(list_of_filenames):\n",
    "    return bool([elem for elem in list_of_filenames if elem.endswith(\".java\")])\n",
    "def timestamp():\n",
    "    return int(datetime.now().timestamp() * 1000 // 1)\n",
    "def load_checkpoints():\n",
    "    if os.path.exists(CHECKPOINTS_PATH):\n",
    "        with open(CHECKPOINTS_PATH, 'r') as checkpoint_file:\n",
    "            lines = checkpoint_file.readlines()\n",
    "            lines = [line.strip() for line in lines]\n",
    "            return lines\n",
    "    else:\n",
    "        return []\n",
    "def save_checkpoint(path):\n",
    "    with open(CHECKPOINTS_PATH, 'a') as checkpoint_file:\n",
    "        checkpoint_file.write(path + \"\\n\")\n",
    "    logger.info(f\"saved {path}\")\n",
    "\n",
    "def run_bohr(repo_path, file_name):\n",
    "    checkpoints = load_checkpoints()\n",
    "    for workdir, repo_list, files in os.walk(repo_path):\n",
    "        java_files = [file for file in files if file.endswith(\".java\")]\n",
    "        for file in java_files:\n",
    "            java_file_path = f\"{workdir}/{file}\"\n",
    "            if java_file_path in checkpoints:\n",
    "                logger.info(f\"skipping {java_file_path}\")\n",
    "                continue\n",
    "            ms = timestamp()\n",
    "            subprocess.call(['java', '-jar', 'bohr.jar', java_file_path, f\"{file_name}_{ms}\"])\n",
    "            save_checkpoint(java_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoints_run_bohr(repo_path: str):\n",
    "    csv_path = \"data/java_files.csv\"\n",
    "    first_line = False if os.path.exists(csv_path) else True\n",
    "    row_dict = {\"path\": repo_path}\n",
    "    # Save to csv\n",
    "    with open(csv_path, 'a') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=row_dict.keys())\n",
    "        if first_line == True:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture mylogs\n",
    "logger.info(\"Started!\")\n",
    "workdir, repo_list, _ = next(os.walk(\"../repos\"))\n",
    "for repo in repo_list:\n",
    "    repo_path = f\"{os.path.abspath(workdir)}/{repo}\"\n",
    "    run_bohr(repo_path, f\"./bohr_reports/{repo}/{repo}\")\n",
    "logger.info(\"Finished!\")\n",
    "with open('bohr_run.txt') as f:\n",
    "    f.write(mylogs.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
